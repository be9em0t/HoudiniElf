{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8557ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded config from: \n",
      "/Users/dunevv/WorkLocal/_AI_/HoudiniElf/tools_Didka/Notebooks/lang_pipeline.ini\n"
     ]
    }
   ],
   "source": [
    "# Minimal test notebook for the AI agent\n",
    "# - INI reading (small subset)\n",
    "# - File import (tab-delimited, similar to pipeline)\n",
    "# - AI placeholder cells (to implement llm_transform and prompt templates)\n",
    "# - Export example\n",
    "\n",
    "import configparser\n",
    "import ast\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def _parse_list_option(val):\n",
    "    if not val:\n",
    "        return []\n",
    "    try:\n",
    "        parsed = ast.literal_eval(val)\n",
    "        if isinstance(parsed, (list, tuple)):\n",
    "            return [str(x).strip() for x in parsed]\n",
    "    except Exception:\n",
    "        return [c.strip() for c in str(val).split(',') if c.strip()]\n",
    "    return []\n",
    "\n",
    "\n",
    "def find_config(name=\"lang_pipeline.ini\"):\n",
    "    p = Path.cwd()\n",
    "    for _ in range(6):\n",
    "        candidate = p / name\n",
    "        if candidate.exists():\n",
    "            return candidate\n",
    "        p = p.parent\n",
    "    return next(Path.cwd().rglob(name), None)\n",
    "\n",
    "\n",
    "cfg_path = find_config()\n",
    "CONFIG = {}\n",
    "if cfg_path:\n",
    "    cp = configparser.ConfigParser()\n",
    "    cp.read(cfg_path)\n",
    "    if 'pipeline' in cp:\n",
    "        sec = cp['pipeline']\n",
    "        CONFIG['source'] = sec.get('source', None)\n",
    "        CONFIG['source_browser'] = sec.getboolean('source_browser', fallback=True)\n",
    "        CONFIG['preview'] = sec.getboolean('preview', fallback=True)\n",
    "        CONFIG['preview_rows'] = sec.getint('preview_rows', fallback=20)\n",
    "        CONFIG['columns_export_filter'] = sec.getboolean('columns_export_filter', fallback=False)\n",
    "        CONFIG['columns_export'] = _parse_list_option(sec.get('columns_export', ''))\n",
    "        # agent placeholders + Ollama settings\n",
    "        CONFIG['ai_provider'] = sec.get('ai_provider', 'ollama')\n",
    "        CONFIG['ai_model'] = sec.get('ai_model', 'mistral-small3.2')\n",
    "        CONFIG['ai_ollama_url'] = sec.get('ai_ollama_url', 'http://localhost:11434')\n",
    "        CONFIG['ai_timeout'] = sec.getint('ai_timeout', fallback=30)\n",
    "        CONFIG['ai_retries'] = sec.getint('ai_retries', fallback=1)\n",
    "        CONFIG['ai_structured_response'] = sec.getboolean('ai_structured_response', fallback=True)\n",
    "        CONFIG['ai_batch_size'] = sec.getint('ai_batch_size', fallback=20)\n",
    "        # new: temperature (float)\n",
    "        try:\n",
    "            CONFIG['ai_temperature'] = float(sec.get('ai_temperature', '0.2'))\n",
    "        except Exception:\n",
    "            CONFIG['ai_temperature'] = 0.2\n",
    "        CONFIG['custom_prompt'] = sec.get('custom_prompt', '')\n",
    "    print(f\"Loaded config from: \\n{cfg_path}\")\n",
    "else:\n",
    "    print(\"No lang_pipeline.ini found; using defaults\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5c222bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured (INI) source used: /Users/dunevv/WorkLocal/_AI_/HoudiniElf/tools_Didka/test_files/sources/Process_names_LLMoutput_mini_numbered_cut.csv\n"
     ]
    }
   ],
   "source": [
    "# File selection (interactive or from INI)\n",
    "import platform, subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "if not CONFIG.get('source_browser', True) and CONFIG.get('source'):\n",
    "    input_path = Path(CONFIG['source'])\n",
    "    if not input_path.exists():\n",
    "        raise FileNotFoundError(f\"Configured (INI) source not found: {input_path}\")\n",
    "    print(\"Configured (INI) source used:\", input_path)\n",
    "else:\n",
    "    try:\n",
    "        from tools.ui_native import pick_file\n",
    "    except Exception:\n",
    "        def pick_file(filter_str=None):\n",
    "            system = platform.system()\n",
    "            if system == \"Darwin\":\n",
    "                script = '''\n",
    "                set theFile to choose file\n",
    "                POSIX path of theFile\n",
    "                '''\n",
    "                res = subprocess.run([\"osascript\", \"-e\", script], capture_output=True, text=True)\n",
    "                return res.stdout.strip()\n",
    "            elif system == \"Windows\":\n",
    "                ps_script = r'''\n",
    "                Add-Type -AssemblyName System.Windows.Forms\n",
    "                $ofd = New-Object System.Windows.Forms.OpenFileDialog\n",
    "                $ofd.Filter = \"All files (*.*)|*.*\"\n",
    "                if ($ofd.ShowDialog() -eq \"OK\") { Write-Output $ofd.FileName }\n",
    "                '''\n",
    "                res = subprocess.run([\"powershell\", \"-NoProfile\", \"-Command\", ps_script], capture_output=True, text=True)\n",
    "                return res.stdout.strip()\n",
    "            else:\n",
    "                raise NotImplementedError(\"No native file dialog for this OS\")\n",
    "\n",
    "    pick_path = pick_file(\"CSV files (*.csv)|*.csv\")\n",
    "    if not pick_path:\n",
    "        raise FileNotFoundError(\"No file selected\")\n",
    "\n",
    "    input_path = Path(pick_path)\n",
    "    print(f\"Selected input file: \\n{input_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c22dd8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header: \n",
      "['ID', 'name', 'language', 'translation', 'confidence', 'breakdown', 'Remaining', 'Unallowed_characters', 'transliterations', 'Unmapped_in_transliterions']\n",
      "\n",
      "Imported 41 rows (41 lines read).\n",
      "No malformed lines found.\n"
     ]
    }
   ],
   "source": [
    "# Line-by-line import (tab-delimited)\n",
    "import csv\n",
    "\n",
    "rows = []\n",
    "bad_rows = []\n",
    "total_lines = 0\n",
    "with input_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "    reader = csv.reader(f, delimiter=\"\\t\", quotechar='\"', escapechar='\\\\')\n",
    "    try:\n",
    "        header = next(reader)\n",
    "    except StopIteration:\n",
    "        header = []\n",
    "    for line_number, line in enumerate(reader, start=2):\n",
    "        total_lines += 1\n",
    "        if len(line) == len(header):\n",
    "            rows.append(dict(zip(header, line)))\n",
    "        elif len(line) > len(header) and len(line) % len(header) == 0:\n",
    "            for i in range(0, len(line), len(header)):\n",
    "                subline = line[i:i+len(header)]\n",
    "                rows.append(dict(zip(header, subline)))\n",
    "        else:\n",
    "            bad_rows.append((line_number, line))\n",
    "\n",
    "expected_columns = header if 'header' in locals() else []\n",
    "print(f\"Header: \\n{expected_columns}\\n\")\n",
    "print(f\"Imported {len(rows)} rows ({total_lines} lines read).\")\n",
    "if bad_rows:\n",
    "    print(f\"{len(bad_rows)} malformed lines found.\")\n",
    "else:\n",
    "    print(\"No malformed lines found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f8fb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM transform failed: name 'llm_transform' is not defined\n",
      "Proceeding with 41 rows (marked ai_notes='llm_error').\n"
     ]
    }
   ],
   "source": [
    "# AI adapter (batched no-op)\n",
    "# Calls the model in batches for testing/debugging but DOES NOT modify rows or add columns.\n",
    "import subprocess, json, math, time\n",
    "\n",
    "\n",
    "def call_ollama_run(model, prompt, timeout=CONFIG.get('ai_timeout', 30)):\n",
    "    cmd = [\"ollama\", \"run\", model]\n",
    "    try:\n",
    "        proc = subprocess.run(cmd, input=prompt.encode('utf-8'), stdout=subprocess.PIPE, stderr=subprocess.PIPE, timeout=timeout)\n",
    "    except Exception as e:\n",
    "        return None, f\"ollama-run-failed: {e}\"\n",
    "    out = proc.stdout.decode('utf-8', errors='replace').strip()\n",
    "    if proc.returncode != 0:\n",
    "        return None, proc.stderr.decode('utf-8', errors='replace').strip()\n",
    "    return out, None\n",
    "\n",
    "\n",
    "def llm_transform(records):\n",
    "    \"\"\"Batched model invocation that does not modify rows.\n",
    "    Returns the original records unchanged. Prints per-batch outputs for inspection.\n",
    "    \"\"\"\n",
    "    if not records:\n",
    "        return []\n",
    "\n",
    "    batch_size = max(1, CONFIG.get('ai_batch_size', 20))\n",
    "    model = CONFIG.get('ai_model', 'mistral-small3.2')\n",
    "    outputs = []\n",
    "    for start in range(0, len(records), batch_size):\n",
    "        end = min(start + batch_size, len(records))\n",
    "        batch = records[start:end]\n",
    "        # Keep payload small by including only indices and names\n",
    "        items = [{\"idx\": i - start, \"name\": r.get('name', '')} for i, r in enumerate(batch, start=start)]\n",
    "        prompt = (\n",
    "            f\"For the following {len(batch)} items return a JSON array of objects with fields 'idx' and 'ai_notes' (short string). \"\n",
    "            \"Only return the JSON array and nothing else.\\n\\nINPUT:\\n\" + json.dumps(items, ensure_ascii=False)\n",
    "        )\n",
    "        out, err = call_ollama_run(model, prompt, timeout=CONFIG.get('ai_timeout', 30))\n",
    "        if err:\n",
    "            print(f\"Batch {start+1}-{end}: Ollama error: {err}\")\n",
    "            outputs.append({'start': start, 'end': end, 'ok': False, 'error': err})\n",
    "            continue\n",
    "        # try to parse JSON but DO NOT modify the rows\n",
    "        try:\n",
    "            parsed = json.loads(out)\n",
    "            outputs.append({'start': start, 'end': end, 'ok': True, 'parsed': parsed})\n",
    "            print(f\"Batch {start+1}-{end}: parsed {len(parsed)} items\")\n",
    "        except Exception:\n",
    "            outputs.append({'start': start, 'end': end, 'ok': False, 'raw_len': len(out)})\n",
    "            print(f\"Batch {start+1}-{end}: could not parse JSON response (raw length {len(out)}).\")\n",
    "        time.sleep(0.1)\n",
    "    print(f\"Completed {math.ceil(len(records)/batch_size)} batches (batch_size={batch_size}).\")\n",
    "    return records\n",
    "\n",
    "# Run a quick transform on the imported rows (for interactive testing)\n",
    "processed_rows = llm_transform(rows)\n",
    "print(f\"Processed {len(processed_rows)} rows via llm_transform (batched noop).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2da3a20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of transformed rows:\n",
      "ID                                name language        translation confidence                                                                                                                                                                                      breakdown Remaining Unallowed_characters transliterations Unmapped_in_transliterions  ai_notes\n",
      "                       Achraf Rent Car      ARA  تأجير سيارات أشرف         85                                                                             Rent Car' translates to تأجير سيارات which clarifies the service offered, while preserving the brand name 'Achraf.                                                                            llm_error\n",
      "                        Achraf rohdine      ARA        أشرف روهدين         90                                                                                                                       Transliterated as a proper noun, maintaining the original pronunciation.                                                                            llm_error\n",
      "                           Achraf Soft      ARA          أشرف سوفت         95                                                                                                                             Transliteration of the brand name 'Soft' to preserve its identity.                                                                            llm_error\n",
      "              Dar El Mizan دار الميزان      ARA        دار الميزان         90                                      The name 'Dar El Mizan' is transliterated as 'دار الميزان'. The term 'دار' means 'house' or 'place', which is a common term in Arabic for establishments.                                                                            llm_error\n",
      "           Dar Lbacha دار الباشا برشيد      ARA   دار الباشا برشيد         90 Dar Lbacha' is transliterated to 'دار الباشا برشيد'. Here, 'الباشا' refers to a title of respect, indicating the establishment's significance. The addition of 'برشيد' specifies its location.                                                                            llm_error\n",
      "                     Darb Omar درب عمر      ARA            درب عمر         95                                                    Darb Omar' translates directly to 'درب عمر'. The word 'درب' means path or way, commonly used in place names across Arabic-speaking regions.                                                                            llm_error\n",
      "                         Darna - دارنا      ARA              دارنا        100                                                               Darna - دارنا' retains its form as it translates directly to mean 'Our House'. This reflects a sense of community and belonging.                                                                            llm_error\n",
      "                           Debdou دبدو      ARA               دبدو        100                                                                     Debdou' is transliterated as it stands since it's a proper noun referring to a specific place. No translation needed here.                                                                            llm_error\n",
      "                 Derb Rabat درب الرباط      ARA         درب الرباط         90                        The name 'Derb' translates to 'path' or 'way', and is commonly used in Arabic to denote streets or alleys, while 'Rabat' remains transliterated as it is a proper noun.                                                                            llm_error\n",
      "   Douche Ben Diban دوش رشاشات بنديبان      ARA دوش رشاشات بنديبان         85                                       Douche' refers to a shower, which can be understood in Arabic. The rest of the name is transliterated as it represents a brand or specific product line.                                                                            llm_error\n"
     ]
    }
   ],
   "source": [
    "# Quick preview of processed rows\n",
    "import pandas as pd\n",
    "\n",
    "if processed_rows:\n",
    "    df = pd.DataFrame(processed_rows)\n",
    "    print(\"Preview of transformed rows:\")\n",
    "    print(df.head(10).to_string(index=False))\n",
    "else:\n",
    "    print(\"No processed rows to preview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ee260b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export result (tab-delimited) — safe overwrite, original columns only\n",
    "import csv\n",
    "\n",
    "export_fieldnames = list(expected_columns)\n",
    "output_suffix = \"_agent_test_out\"\n",
    "stem = input_path.stem\n",
    "ext = input_path.suffix\n",
    "output_path = input_path.with_name(f\"{stem}{output_suffix}{ext}\")\n",
    "print(f\"Exporting to: {output_path}\")\n",
    "\n",
    "with output_path.open(\"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=export_fieldnames, delimiter=\"\\t\", extrasaction='ignore', restval='')\n",
    "    writer.writeheader()\n",
    "    writer.writerows(processed_rows)\n",
    "\n",
    "print(\"Export complete (original columns only)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc36aac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting to: /Users/dunevv/WorkLocal/_AI_/HoudiniElf/tools_Didka/test_files/sources/Process_names_LLMoutput_mini_numbered_cut_agent_test_out.csv\n",
      "Export complete\n"
     ]
    }
   ],
   "source": [
    "# Export result (tab-delimited)\n",
    "import csv\n",
    "\n",
    "# No AI columns are added in this test (keep original columns only)\n",
    "new_cols = ()\n",
    "export_fieldnames = list(expected_columns)\n",
    "\n",
    "output_suffix = \"_agent_test_out\"\n",
    "stem = input_path.stem\n",
    "ext = input_path.suffix\n",
    "output_path = input_path.with_name(f\"{stem}{output_suffix}{ext}\")\n",
    "print(f\"Exporting to: {output_path}\")\n",
    "\n",
    "with output_path.open(\"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=export_fieldnames, delimiter=\"\\t\", extrasaction='ignore', restval='')\n",
    "    writer.writeheader()\n",
    "    writer.writerows(processed_rows)\n",
    "\n",
    "print(\"Export complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
